{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571f209-db40-493c-a035-901ae1fd3227",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91026d-9a8e-4435-8f2f-b81b9190d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca66cd1-5e16-4041-96d0-a46014216fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack for those using local notebooks vs. Jupyter\n",
    "from pathlib import Path\n",
    "if Path(\"../sva\").exists():\n",
    "    import sys\n",
    "    sys.path.append(\"..\")\n",
    "else:\n",
    "    ! pip install git+https://github.com/matthewcarbone/ScientificValueAgent@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97685c-3980-4e41-8ced-5db4592bdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the various experiments we need for the notebook\n",
    "from sva.experiments import SimpleSigmoid\n",
    "\n",
    "# Import the helper functions for Gaussian Processes\n",
    "from sva.models.gp import EasySingleTaskGP, EasyFixedNoiseGP\n",
    "from sva.models.gp.plotting import plot_1d_gp\n",
    "\n",
    "# Other utilities\n",
    "from sva.utils import random_indexes, set_mpl_grids, set_mpl_defaults, seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cc537-dd50-4348-98b3-b577ad67e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_mpl_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3b5c3-256a-4a48-b6ac-6434fb44a1ab",
   "metadata": {},
   "source": [
    "# Simple GP with and without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203ee42-5963-4ed3-b2d8-09293f7083ca",
   "metadata": {},
   "source": [
    "Let's begin with the simplest Gaussian Processes. There are two flavors of these. One with fixed noise (where noise is provided) and the second is where noise is inferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c7ac4-a84e-4496-836d-509b95cabe36",
   "metadata": {},
   "source": [
    "## Ground truth with exact mean, with and without errorbars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f3943-54ac-4b31-9185-f3a0f7293efe",
   "metadata": {},
   "source": [
    "Consider a sigmoid function which is completely deterministic:\n",
    "\n",
    "$$ f(x; a) = \\frac{2}{1 + e^{-ax}} - 1. $$\n",
    "\n",
    "If we know what the error bars are on each data point, we can use a `FixedNoiseGP` to force the GP to have a given uncertainty at every point. However, this is usually not the case, and it usually makes the most sense to _infer_ the noise using a `SingleTaskGP`, which will attempt to learn the uncertainty at every point. Below, we showcase what this looks like:\n",
    "\n",
    "- A `SingleTaskGP` where noise is inferred.\n",
    "- A `FixedNoiseGP` with $\\sigma=0.2|x|.$\n",
    "- A `FixedNoiseGP` with a poor estimate for the noise $\\sigma=10^{-4}|x|.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d8879-0f32-4e68-a431-81451e9f21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(124)\n",
    "sigmoid = SimpleSigmoid(a=10.0, noise=lambda x: 0.2 * np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418aa7d6-d1e5-4c23-8340-2981fa429fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "\n",
    "x = np.linspace(-1, 1, 500).reshape(-1, 1)\n",
    "y, yvar = sigmoid(x.reshape(-1, 1))\n",
    "train_indexes = random_indexes(x.shape[0], samples=10)\n",
    "x_train = x[train_indexes, :]\n",
    "y_train = y[train_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad13a0-f11e-4b9f-bdeb-2b04e73ab619",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_truth, _ = sigmoid.truth(x.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b271e-3898-4618-9b0d-e2eac3f056d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single task GP. Homoskedastic noise is inferred from the data.\n",
    "gp1 = EasySingleTaskGP.from_default(x_train, y_train)\n",
    "gp1.fit_mll()\n",
    "samples1 = gp1.sample(x, samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ab6b8-7106-4788-98c9-14fc516e8cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed noise GP. Noise is provided a priori from the data explicitly in the\n",
    "# form of error bars. Here we use the correct experimental noise to demonstrate\n",
    "# the power of a fixed noise GP when the noise is known accurately.\n",
    "gp2 = EasyFixedNoiseGP.from_default(x_train, y_train, Yvar=(0.2 * np.abs(x_train))**2)\n",
    "gp2.fit_mll()\n",
    "samples2 = gp2.sample(x, samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d49fab-44f5-44d9-b18b-bf1364b10c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed noise GP. Here we show how badly things can go if you set the noise \n",
    "# incorrectly, since the GP is going to be force to assume that noise is correct\n",
    "gp3 = EasyFixedNoiseGP.from_default(x_train, y_train, Yvar=(1e-4 * np.abs(x_train))**2)\n",
    "gp3.fit_mll()\n",
    "samples3 = gp3.sample(x, samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25c429-195f-4670-9af1-0658d693a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(6, 1), sharey=True)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.set_title(\"SingleTaskGP\")\n",
    "plot_1d_gp(ax, train_X=x_train, train_Y=y_train, train_Yvar=None, test_X=x, gp_samples=samples1)\n",
    "ax.plot(x, y_truth, color=\"black\", linewidth=0.2)\n",
    "ax.set_ylabel(\"$f(x)$\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.set_title(\"FixedNoiseGP\")\n",
    "plot_1d_gp(ax, train_X=x_train, train_Y=y_train, train_Yvar=(0.2 * np.abs(x_train))**2, test_X=x, gp_samples=samples2)\n",
    "ax.plot(x, y_truth, color=\"black\", linewidth=0.2)\n",
    "ax.set_xlabel(\"$x$\")\n",
    "\n",
    "ax = axs[2]\n",
    "ax.set_title(\"FixedNoiseGP (2)\")\n",
    "plot_1d_gp(ax, train_X=x_train, train_Y=y_train, train_Yvar=(1e-4 * np.abs(x_train))**2, test_X=x, gp_samples=samples3)\n",
    "ax.plot(x, y_truth, color=\"black\", linewidth=0.2)\n",
    "\n",
    "ax.set_ylim(-1.5, 1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc66100-2ce1-4881-84fc-f7fc42e1fb39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
